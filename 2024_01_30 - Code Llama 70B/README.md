# Running Code LLama 70B via serverless APIs
This demo explores running Meta's 70B parameter model via serverless APIs from Code Llama via Together and Anyscale.

Part 1: Set up a simple runnable to output Python via Code Llama 70B (01_Running_CodeLlama70b.ipynb)
Part 2: Swap Code Llama 70b for GPT-4 in one part of an agent chain (02_CodeLlama_LangGraph_agent.ipynb)

You can [watch the video on YouTube](https://youtu.be/qvkXPt8lcEE)

# Project Setup
You will need to create a .env file with your own keys. I have provided an example at .env.example

The demo files can all be run as Jupyter notebooks.

